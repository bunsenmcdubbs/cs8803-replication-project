{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Lexicon\n",
    "\n",
    "The original paper authors use a sentiment lexicon from MQPA - [Subjectivity Lexicon](mpqa.cs.pitt.edu/lexicons/subj_lexicon/).\n",
    "\n",
    "> We used MPQA sentiment lexicon (Wilson et al., 2005) for our study, which contains 2,718 positive and 4,912 negative lexicons.\n",
    "\n",
    "The lexicon is a single file with one term per row. Example:\n",
    "```\n",
    "type=weaksubj len=1 word1=abjure pos1=verb stemmed1=y priorpolarity=negative\n",
    "```\n",
    "\n",
    "Consulting the provided README points us to look at the last element/key `priorpolarity` to define our positive/negative lexicon. With a couple simple invocations, we can see that this methodology produces a lexicon that matches that of the original authors.[<sup>caveat</sup>](#Size-of-the-lexicon)\n",
    "\n",
    "```\n",
    "$ cat <mpqa-lexicon-file> | grep 'priorpolarity=positive' | wc -l\n",
    "    2718\n",
    "```\n",
    "\n",
    "```\n",
    "$ cat <mpqa-lexicon-file> | grep 'priorpolarity=negative' | wc -l\n",
    "    4912 \n",
    "```\n",
    "\n",
    "(See [Notes](#Notes) for characteristics of the dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookup Table from Lexicon\n",
    "\n",
    "Let's load the lexicon into memory and create an efficient method for lookup.\n",
    "\n",
    "The lexicon includes word stems and parts of speech in addition to the actual word. Because the papers' authors to do describe how they used the lexicon, we will assume all possible features were used. Parses from Stanford CoreNLP (as well as annotated data provided by the authors) include lemmas and POS data so we will match tokens with lexicon entities with all available data.\n",
    "\n",
    "This means that we only care about the following fields each entry in the lexicon:\n",
    " - `word1` - The word or stem (different than lemma!)\n",
    " - `pos1` - Part of speech will be `adj`, `adverb`, `anypos`, `noun`, or `verb`\n",
    " - `stemmed1` - True or False, is this entry a stem?\n",
    " - `priorpolarity` - `positive`, `negative`, `neutral`, or `both` - We will only use `positive` and `negative`\n",
    "\n",
    "The MPQA sentiment lexicon uses a much more general set of POS labels than CoreNLP. This means that we will need a mapping between the two. (`anypos` is any part of speech)\n",
    "```\n",
    "$ cat subjclueslen1-HLTEMNLP05.tff | grep -o 'pos1=[a-z]*' | sort | uniq\n",
    "pos1=adj\n",
    "pos1=adverb\n",
    "pos1=anypos\n",
    "pos1=noun\n",
    "pos1=verb\n",
    "```\n",
    "\n",
    "Additionally, the lexicon uses stemming and CoreNLP's annotations use lemmas. Although similar, [they are not the same](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html). Instead, we'll match the tokens either a whole word or a stem matches either the whole token or the lemma (in addition to part of speech).\n",
    "\n",
    "We'll create a mapping of word/stem to (stem?, POS) to sentiment mapping. For efficient prefix lookups, we'll use a trie - specifically, Google's implementation [`pygtrie`](https://github.com/google/pygtrie) which is a drop-in replacement for Python dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class POS(Enum):\n",
    "    ANY_POS = 'anypos'\n",
    "    ADJ = 'adj'\n",
    "    ADVERB = 'adverb'\n",
    "    NOUN = 'noun'\n",
    "    VERB = 'verb'\n",
    "    \n",
    "class Sentiment(Enum):\n",
    "    POSITIVE = 'positive'\n",
    "    NEGATIVE = 'negative'\n",
    "    \n",
    "valid_sentiments = set([s.value for s in Sentiment.__members__.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygtrie\n",
    "\n",
    "trie = pygtrie.CharTrie()\n",
    "\n",
    "def add_entry(text, pos, is_stem, sentiment):\n",
    "    if text not in trie:\n",
    "        trie[text] = dict()\n",
    "    assert (pos, is_stem) not in trie[text], '{} already exists'.format((text, pos, is_stem))\n",
    "    trie[text][(pos, is_stem)] = sentiment\n",
    "\n",
    "def get_sentiment(text, pos):\n",
    "    if trie.has_key(text):\n",
    "        if (pos, False) in trie[text]:\n",
    "            return trie[text][pos, False]\n",
    "        elif (pos, True) in trie[text]:\n",
    "            return trie[text][pos, True]\n",
    "    else:\n",
    "        for _, entries in reversed(list(trie.prefixes(text))):\n",
    "            if (pos, True) in entries:\n",
    "                return entries[pos, True]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, ('autocratic', <POS.ADJ: 'adj'>, False) already exists\n",
      "Skipping, ('boast', <POS.VERB: 'verb'>, True) already exists\n",
      "Skipping, ('brazenly', <POS.ANY_POS: 'anypos'>, False) already exists\n",
      "Skipping, ('brazenness', <POS.NOUN: 'noun'>, False) already exists\n",
      "Skipping, ('cohesive', <POS.ADJ: 'adj'>, False) already exists\n",
      "Skipping, ('constructive', <POS.ADJ: 'adj'>, False) already exists\n",
      "Skipping, ('disinterested', <POS.ADJ: 'adj'>, False) already exists\n",
      "Skipping, ('disown', <POS.VERB: 'verb'>, True) already exists\n",
      "Skipping, ('distinctive', <POS.ADJ: 'adj'>, False) already exists\n",
      "Skipping, ('famed', <POS.ADJ: 'adj'>, False) already exists\n",
      "Skipping, ('hasty', <POS.ADJ: 'adj'>, False) already exists\n",
      "Skipping, ('hegemony', <POS.NOUN: 'noun'>, False) already exists\n",
      "Skipping, ('isolation', <POS.NOUN: 'noun'>, False) already exists\n",
      "Skipping, ('killer', <POS.NOUN: 'noun'>, False) already exists\n",
      "Skipping, ('lecher', <POS.NOUN: 'noun'>, False) already exists\n",
      "Skipping, ('lure', <POS.VERB: 'verb'>, True) already exists\n",
      "Skipping, ('mesmerizing', <POS.ANY_POS: 'anypos'>, False) already exists\n",
      "Skipping, ('patient', <POS.ADJ: 'adj'>, False) already exists\n",
      "Skipping type=strongsubj len=1 word1=pervasive pos1=adj stemmed1=n m priorpolarity=negative\n",
      " dictionary update sequence element #5 has length 1; 2 is required\n",
      "Skipping, ('perturbed', <POS.ADJ: 'adj'>, False) already exists\n",
      "Skipping type=strongsubj len=1 word1=pervasive pos1=noun stemmed1=n m priorpolarity=negative\n",
      " dictionary update sequence element #5 has length 1; 2 is required\n",
      "Skipping, ('perturbed', <POS.ADJ: 'adj'>, False) already exists\n"
     ]
    }
   ],
   "source": [
    "filepath = '../../data/subjectivity_clues_hltemnlp05/subjclueslen1-HLTEMNLP05.tff'\n",
    "with open(filepath, 'r') as f:\n",
    "    for raw_entry in f:\n",
    "        try:\n",
    "            entry = dict((pair.split('=')) for pair in raw_entry.strip().split(' '))\n",
    "        except ValueError as e:\n",
    "            print('Skipping', raw_entry, e)\n",
    "        if entry['priorpolarity'] in valid_sentiments:\n",
    "            try:\n",
    "                add_entry(entry['word1'], POS(entry['pos1']), entry['stemmed1']=='y', Sentiment(entry['priorpolarity']))\n",
    "            except AssertionError as e:\n",
    "                print('Skipping,', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6450"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(<POS.ADJ: 'adj'>, False): <Sentiment.POSITIVE: 'positive'>,\n",
       " (<POS.NOUN: 'noun'>, False): <Sentiment.POSITIVE: 'positive'>,\n",
       " (<POS.VERB: 'verb'>, True): <Sentiment.POSITIVE: 'positive'>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie['help']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Calculating\" sentiment label for given span\n",
    "\n",
    "For spans of text, the authors\n",
    "> define the sentiment label ... to be positive if it contains more words that appear in teh positive sentiment lexicon than that appear in the negative one [and vice versa]\n",
    "\n",
    "Easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_sentiment_label(tokens):\n",
    "    sentiment = Counter()\n",
    "    for token in tokens:\n",
    "        pos = ptb2ezpos(token['pos'])\n",
    "        ts = get_sentiment(token['originalText'], pos) or get_sentiment(token['lemma'], pos) if 'lemma' in token else None\n",
    "        if ts is not None:\n",
    "            sentiment[ts] += 1\n",
    "    return sentiment.most_common()[0][0] if len(sentiment) > 0 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also have to create the mappings from CoreNLP's tag set ([Penn Treebank tags](http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)] to the much simplier tags used in the MPQA sentiment lexicons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptb2ezpos(ptb_tag):\n",
    "    tag = ptb_tag.lower()[:1]\n",
    "    if tag == 'nn': # NN, NNS, NNP, NNPS\n",
    "        return POS.NOUN\n",
    "    elif tag == 'vb': # VB, VBD, VBG, VBN, VBP, VBZ\n",
    "        return POS.VERB\n",
    "    elif tag == 'rb': # RB, RBR, RBS\n",
    "        return POS.ADVERB\n",
    "    elif tag == 'jj': # JJ, JJR, JJS\n",
    "        return POS.ADJ\n",
    "    return POS.ANY_POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it out with a file from MPQA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycorenlp import StanfordCoreNLP\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "test_file = '../../data/database.mpqa.3.0/docs/20010926/23.17.57-23406'\n",
    "text = open(test_file, 'r').read()\n",
    "output = nlp.annotate(text, properties={\n",
    "    'annotators': 'ner',\n",
    "    'outputFormat': 'json'\n",
    "})\n",
    "sentences = output['sentences']\n",
    "\n",
    "def get_text(tokens_slice):\n",
    "    raw_text = []\n",
    "    for token in tokens_slice:\n",
    "        raw_text.append(token['originalText'])\n",
    "        raw_text.append(token['after'])\n",
    "    return ''.join(raw_text[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'after': '',\n",
       " 'before': '',\n",
       " 'characterOffsetBegin': 0,\n",
       " 'characterOffsetEnd': 6,\n",
       " 'index': 1,\n",
       " 'lemma': 'TAIPEI',\n",
       " 'ner': 'LOCATION',\n",
       " 'originalText': 'TAIPEI',\n",
       " 'pos': 'NNP',\n",
       " 'word': 'TAIPEI'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]['tokens'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something simple, what's the sentiment for each of the sentences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment.NEGATIVE\n",
      "TAIPEI, Sept 26 (AFP) -- Taiwan President Chen Shui-bian on Wednesday reiterated Taipei's full support for the United States as Washington prepared to launch reprisals against Afghanistan.\n",
      "\n",
      "Sentiment.NEGATIVE\n",
      "\"On behalf of the government and people of the Republic of China (Taiwan's official name), I would like to extend our full support to the George W. Bush administration in its any decision and act against terrorists,\" Chen said while meeting Oregon governor John Kitzhaber.\n",
      "\n",
      "None\n",
      "Taiwan \"would not stand idly by\" because \"the attacks were not only a challenge to the US but also a disruption of peace for mankind,\" Chen said in a statement released by the presidential office.\n",
      "\n",
      "None\n",
      "\"The ROC government will be with the US government firmly.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences[:4]:\n",
    "    sent = get_sentiment_label(sentence['tokens'])\n",
    "    print('{}\\n{}\\n'.format(sent, get_text(sentence['tokens'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e2e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/andrew/Documents/college/cs8803-css/replication-project/code/src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "preproc_path = os.path.abspath(os.path.join('..'))\n",
    "print(preproc_path)\n",
    "if preproc_path not in sys.path:\n",
    "    sys.path.append(preproc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from base_models import sentiment_lexicon\n",
    "\n",
    "importlib.reload(sentiment_lexicon);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<Sentiment.NEGATIVE: 'negative'>, Counter({None: 31, <Sentiment.NEGATIVE: 'negative'>: 1}))\n",
      "TAIPEI, Sept 26 (AFP) -- Taiwan President Chen Shui-bian on Wednesday reiterated Taipei's full support for the United States as Washington prepared to launch reprisals against Afghanistan.\n",
      "\n",
      "(<Sentiment.NEGATIVE: 'negative'>, Counter({None: 52, <Sentiment.NEGATIVE: 'negative'>: 1}))\n",
      "\"On behalf of the government and people of the Republic of China (Taiwan's official name), I would like to extend our full support to the George W. Bush administration in its any decision and act against terrorists,\" Chen said while meeting Oregon governor John Kitzhaber.\n",
      "\n",
      "(None, Counter({None: 41}))\n",
      "Taiwan \"would not stand idly by\" because \"the attacks were not only a challenge to the US but also a disruption of peace for mankind,\" Chen said in a statement released by the presidential office.\n",
      "\n",
      "(None, Counter({None: 13}))\n",
      "\"The ROC government will be with the US government firmly.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sl, sent_count, pos_count = sentiment_lexicon.SentimentLexicon.from_mpqa_file(filepath)\n",
    "for sentence in sentences[:4]:\n",
    "    sent = sl.get_sentiment_label(sentence['tokens'])\n",
    "    print('{}\\n{}\\n'.format(sent, get_text(sentence['tokens'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({<Sentiment.NEGATIVE: 'negative'>: 4898,\n",
       "         <Sentiment.POSITIVE: 'positive'>: 2712})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({<POS.ADJ: 'adj'>: 3000,\n",
       "         <POS.ADVERB: 'adverb'>: 311,\n",
       "         <POS.ANY_POS: 'anypos'>: 1036,\n",
       "         <POS.NOUN: 'noun'>: 2017,\n",
       "         <POS.VERB: 'verb'>: 1246})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "### Size of the lexicon\n",
    "\n",
    "Although the paper's authors claim the MPQA dataset to contain \"2,718 positive and 4,912 negative lexicons\", it contains a negligible amount fewer unique entities. (Note: this is the loosest definition for uniqueness because reordered fields or other meaningless changes between rows will show up as unique rows under this count).\n",
    "\n",
    "```\n",
    "$ cat <mpqa-lexicon-file> | wc -l\n",
    "    8222\n",
    "```\n",
    "\n",
    "```\n",
    "$ cat <mpqa-lexicon-file> | sort | uniq | wc -l\n",
    "    8209\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({<Sentiment.NEGATIVE: 'negative'>: 4898,\n",
       "         <Sentiment.POSITIVE: 'positive'>: 2712})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([s for entries in trie.values() for s in entries.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interesting quirks (errors?) in the MPQA lexicon\n",
    "\n",
    "I found some strange and seemingly erroneous lines in the lexicon file when first exploring the file. None of these quirks were \"addressed\" in anyway and all replication was performed without altering the original lexicon in any way.\n",
    "\n",
    "The README tells us that the only possible values for `priorpolarity` should be `positive, negative, both, neutral` but that does not turn out to be the case...\n",
    "```\n",
    "$ cat subjclueslen1-HLTEMNLP05.tff | grep -o 'priorpolarity=[a-z]*' | sort | uniq\n",
    "priorpolarity=both\n",
    "priorpolarity=negative\n",
    "priorpolarity=neutral\n",
    "priorpolarity=positive\n",
    "priorpolarity=weakneg\n",
    "```\n",
    "\n",
    "It looks like line 3749 in the lexicon file is the offending entry:\n",
    "```\n",
    "$ cat <mpqa-lexicon-file> | nl | \\grep 'priorpolarity=weakneg'\n",
    "  3749\ttype=weaksubj len=1 word1=impassive pos1=adj stemmed1=n polarity=negative priorpolarity=weakneg\n",
    "```\n",
    "\n",
    "It seems like almost all the entries have the same keys in the same order, but on lines 5549 and 5550 there is a stray `m`:\n",
    "```\n",
    "$ cat <mpqa-lexicon-file> | nl | grep ' m '\n",
    "  5549\ttype=strongsubj len=1 word1=pervasive pos1=adj stemmed1=n m priorpolarity=negative\n",
    "  5550\ttype=strongsubj len=1 word1=pervasive pos1=noun stemmed1=n m priorpolarity=negative\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
